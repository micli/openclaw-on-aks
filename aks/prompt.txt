
Notes:
Most of deployment scripts generated by GitHub Copilot. I interactive with GitHub Copilot for troubleshooting.


需要创建用于部署的 deploy-openclaw-aks.sh 脚本文件，以及用来部署 K8s ConfigMap，service，deployment 的 YAML 文件。
+ 当前目录下，创建两个 YAML 文件用于部署 configMap
+ 当前目录下，创建一个 YAML 文件用来部署 LiteLLM 相关的 deployment，service，ingress
+ 当前目录下，创建一个 YAML 文件用来部署 openclaw 相关的 deployment，service，ingress

deploy-openclaw-aks.sh 在文件头部定义了3个参数：DEPLOY_NAME, openclaw项目的部署名
REGION, 部署 Azure 资源所在的区域
MODELNAME, Azure OpenAI 的模型名称,默认为"gpt-5.2"

利用 DEPLOY_NAME加上“-RG” 来构造资源组的名字
利用 “DEPLOY_NAME”加上“-llmproxy” 来构造用来运行 LiteLLM 的 Deployment 和 Service 名字
利用 “DEPLOY_NAME” 来构造 OpenClaw 的 Deployment 和 Service 名字以上三个参数既可以通过终端传入脚本中，又可以在脚本中直接定义。[前提条件]
已安装并配置好 Azure CLI，并且已登录到 Azure 账户。
已经安装了 kubectl[整体目标]
利用部署在 AKS 上的 LiteLLM Docker 镜像，来反向代理 azure-openai.json 配置文件中定义的 Azure OpenAI 服务请求
在 AKS 上创建一个 Deployment 来运行 OpenClaw 镜像，并配置其指向 LiteLLM 服务。
让 OpenClaw 容器能够通过 LiteLLM 反向代理访问 Azure OpenAI 服务。
Azure 资源创建通过 Azure CLI 完成，Kubernetes 对象（ConfigMap、Deployment、Service）通过 kubectl 完成。
配置文件通过 Kubernetes ConfigMap 注入到容器中（不再使用 Azure Files）。[整体要求]
在终端中输出必要的提示信息，让用户了解部署进度和结果。
在终端中采用彩色输出，提升可读性。
在终端中输出最终部署的 OpenClaw Service 的 URL，方便用户访问
使用 Docker 镜像指定来部署容器，如 image: 在 YAML 中。[主要步骤]参考链接：https://zhuanlan.zhihu.com/p/2003026782576714036 的内容，该链接内容采用本地部署, 现在需要迁移到 Azure AKS，并使用 ConfigMap 注入配置。根据azure-openai.json 配置文件，创建支持 LiteLLM 容器运行的配置文件。读取 azure-openai.json 文件，获取 Azure OpenAI 服务的端点和密钥。
在本地生成一个 LiteLLM 配置文件，名为 litellm-config.yaml。
生成一个随机生成的 32 位字符串密钥,赋值给 ${MASTER_KEY}
将 ${MASTER_KEY} 设置到配置文件的“master_key“ 配置项。

创建资源组使用 Azure CLI 创建一个新的资源组，名称为 "${DEPLOY_NAME}-RG"，位置为 "${REGION}"。
在创建资源组之前，检查该资源组是否已经存在。

创建 AKS 集群使用 Azure CLI 检查是否有一个名称为 "${DEPLOY_NAME}-aks" 的 AKS 集群已经存在，如果有就直接使用。
如果不存在，使用 Azure CLI 创建一个新的 AKS 集群，名称为 "${DEPLOY_NAME}-aks"，在资源组 "${DEPLOY_NAME}-RG" 中，节点数为 1~3，节点 VM 大小为 Standard_D2s_v5 或类似（支持容器），位置为 "${REGION}"。
获取 AKS 凭证，使用 az aks get-credentials 配置 kubectl 连接到集群。
创建一个命名空间名为 "openclaw-ns"，如果已存在则使用。

创建 LiteLLM 的 ConfigMap使用 kubectl 在 "openclaw-ns" 命名空间中创建 ConfigMap，名称为 "${DEPLOY_NAME}-llmproxy-config"
从本地文件 litellm-config.yaml 创建（kubectl create configmap ... --from-file=litellm-config.yaml）
或通过 YAML manifest 定义 data 字段包含文件内容。

部署 LiteLLM 到 AKS使用 kubectl 在 "openclaw-ns" 命名空间中创建一个 Deployment，名称为 "${DEPLOY_NAME}-llmproxy"，使用镜像 "litellm/litellm:latest" 从 Docker Hub 拉取。
在容器 spec 中添加 volumes：引用 ConfigMap "${DEPLOY_NAME}-llmproxy-config"
在 volumeMounts 中挂载：mountPath: "/app/config/litellm-config.yaml"，subPath: "litellm-config.yaml"，readOnly: true（只挂载单个文件，避免覆盖目录）
通过容器 command 或 args 启动 LiteLLM：["litellm", "--config", "/app/config/litellm-config.yaml"]
创建一个 LoadBalancer 类型 Service，名称为 "${DEPLOY_NAME}-llmproxy-svc"，暴露端口 8000（LiteLLM 默认端口）或 80，targetPort 对应容器端口。
等待 Service 获得外部 IP 或域名，获取 LiteLLM 的外部 URL（http://<external-ip>:8000 或 https 如果有 TLS）。
命令行彩色输出 LiteLLM Service 的 URL。

执行测试代码，对 LiteLLM 的 Service 发送 Azure OpenAI 对话请求，确认访问是否成功。执行代码：curl -X POST ${LITELLM_URL}/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer ${MASTER_KEY}" -d '{"model": "${MODELNAME}", "messages": [{"role": "user", "content": "Hello"}]}'
输出返回结果，验证是否正常返回（如果成功，说明配置注入和代理正常）。

在本地创建 openclaw 配置文件
配置文件名为：openclaw-config.json，以下是 JSON 格式的配置文件内容，请做替换。{
 "gateway": {
"mode": "local",
"port": 18789,
"token": "${OPENCLAW_TOKEN}"  // 随机生成字符串
 },
 "agents": {
"default": {
   "model": {
      "primary": "litellm/${MODELNAME}"
   },
   "models": {
      "litellm/${MODELNAME}": {
         "alias": "Azure OpenAI ${MODELNAME}"
      }
   }
}
 },
 "models": {
"mode": "merge",
"providers": {
   "litellm": {
      "baseUrl": "http://${DEPLOY_NAME}-llmproxy-svc.openclaw-ns.svc.cluster.local:8000",  // 优先使用集群内部 Service DNS 名称（更稳定、更快、无需公网）
      "apiKey": "${MASTER_KEY}",
      "models": [
         {
            "id": "${MODELNAME}",
            "name": "Azure OpenAI ${MODELNAME}",
            "reasoning": false,
            "input": ["text", "image"],
            "contextWindow": 128000,
            "maxTokens": 16384
         }
      ]
   }
}
 }
}
（注：baseUrl 也可使用外部 URL ${LITELLM_URL}，但内部 DNS 更推荐）

创建 OpenClaw 的 ConfigMap使用 kubectl 在 "openclaw-ns" 命名空间中创建 ConfigMap，名称为 "${DEPLOY_NAME}-openclaw-config"
从本地文件 openclaw-config.json 创建。

部署 OpenClaw 到 AKS使用 kubectl 在 "openclaw-ns" 命名空间中创建一个 Deployment，名称为 "${DEPLOY_NAME}"，使用镜像 "alpine/openclaw:latest" 从 Docker Hub 拉取。
在容器 spec 中添加 volumes：引用 ConfigMap "${DEPLOY_NAME}-openclaw-config"
在 volumeMounts 中挂载：mountPath: "/app/config/openclaw-config.json"，subPath: "openclaw-config.json"，readOnly: true
（可选）添加 readiness/liveness probe 来处理启动时间较长的情况，initialDelaySeconds 可设为 60~180 秒。
创建一个 LoadBalancer 类型 Service，名称为 "${DEPLOY_NAME}-svc"，暴露 OpenClaw 的 Web 端口（假设为 80 或 18789，根据镜像实际端口调整）。
等待 Service 获得外部 IP，获取 OpenClaw 的外部 URL。
命令行彩色输出 OpenClaw Service 的 URL，例如：http://<external-ip> 或 https://<external-ip>。

